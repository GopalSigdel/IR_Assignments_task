{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "345583b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\basan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\basan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\basan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\basan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3fbb369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_url(url):\n",
    "    try:\n",
    "        # Send a GET request to the specified URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            # Find the anchor tag with class \"portal_link\" and text \"Research output\"\n",
    "            research_output_link_element = soup.find(\"a\",\n",
    "                                                     class_=\"portal_link\",\n",
    "                                                     text=\"Research output\")\n",
    "\n",
    "            if research_output_link_element:\n",
    "                # Get the URL linked to the element\n",
    "                research_output_link = research_output_link_element[\"href\"]\n",
    "\n",
    "                # Construct the full URL if it's relative\n",
    "                if research_output_link.startswith(\"/\"):\n",
    "                    research_output_link = \"https://pureportal.coventry.ac.uk\" + research_output_link\n",
    "\n",
    "                # Return the research output URL\n",
    "                return research_output_link\n",
    "            else:\n",
    "                print(\"Error: Research output element not found on the page.\")\n",
    "                return None\n",
    "        else:\n",
    "            # If the request was not successful, print an error message\n",
    "            print(\n",
    "                \"Error: Unable to fetch data from the specified URL. Status code:\",\n",
    "                response.status_code)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that occur during the process\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "797c3eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basan\\AppData\\Local\\Temp\\ipykernel_20320\\3441163301.py:15: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  research_output_link_element = soup.find(\"a\",\n"
     ]
    }
   ],
   "source": [
    "# Define the URL\n",
    "url = \"https://pureportal.coventry.ac.uk/en/organisations/ihw-centre-for-health-and-life-sciences-chls/\"\n",
    "\n",
    "# Call the function and save the result into the url variable\n",
    "url = get_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a16630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0e6a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv():\n",
    "    with open(\"publication.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"Title\", \"Authors\", \"Publication Year\", \"Publication Link\", \"Authors Profile\"])\n",
    "    print(\"CSV file created successfully.\")\n",
    "\n",
    "    \n",
    "def update_csv(database):\n",
    "    current_data = pd.read_csv(database, index_col=\"Unnamed: 0\")\n",
    "    return current_data       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da0af78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_db = pd.read_csv('publication.csv').reset_index().rename(columns={'index':'SN'})\n",
    "\n",
    "# print(f'{sample_db.shape[0]} records were scraped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "800a0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "import string\n",
    "sw = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def tp1(txt):\n",
    "    txt = txt.lower()   # Make lowercase\n",
    "    txt = txt.translate(str.maketrans('','',string.punctuation))   # Remove punctuation marks\n",
    "    txt = lematize(txt)\n",
    "    return txt\n",
    "\n",
    "\n",
    "def fwpt(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    hash_tag = {\"V\": wordnet.VERB, \"R\": wordnet.ADV,\"N\": wordnet.NOUN,\"J\": wordnet.ADJ}         \n",
    "    return hash_tag.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lematize(text):\n",
    "        tkns = nltk.word_tokenize(text)\n",
    "        ax = \"\"\n",
    "        for each in tkns:\n",
    "            if each not in sw:\n",
    "                ax += lemmatizer.lemmatize(each, fwpt(each)) + \" \"\n",
    "        return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62b661d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basan\\AppData\\Local\\Temp\\ipykernel_20320\\2613971725.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.Author = df.Authors.str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Publication Link</th>\n",
       "      <th>Authors Profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>barrier facilitator participation key componen...</td>\n",
       "      <td>Roden, L.</td>\n",
       "      <td>1 Jan 2024</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/publicati...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>doxorubicin alters gprotein couple receptormed...</td>\n",
       "      <td>Lozahic, C.,Maddock, H.,Wheatley, M.,Sandhu, H.</td>\n",
       "      <td>29 Jan 2024</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/publicati...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>human gut microbiota endocrinology paradigm sh...</td>\n",
       "      <td>Turner, M. C.,Morozov, I.</td>\n",
       "      <td>1 Feb 2024</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/publicati...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hatem ali</td>\n",
       "      <td>Hatem Ali</td>\n",
       "      <td>1 Feb 2024</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/h...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sara anisi</td>\n",
       "      <td>Sara Anisi</td>\n",
       "      <td>1 Feb 2024</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/s...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SN                                              Title  \\\n",
       "0   0  barrier facilitator participation key componen...   \n",
       "1   1  doxorubicin alters gprotein couple receptormed...   \n",
       "2   2  human gut microbiota endocrinology paradigm sh...   \n",
       "3   3                                         hatem ali    \n",
       "4   4                                        sara anisi    \n",
       "\n",
       "                                           Authors Publication Year  \\\n",
       "0                                        Roden, L.       1 Jan 2024   \n",
       "1  Lozahic, C.,Maddock, H.,Wheatley, M.,Sandhu, H.      29 Jan 2024   \n",
       "2                        Turner, M. C.,Morozov, I.       1 Feb 2024   \n",
       "3                                        Hatem Ali       1 Feb 2024   \n",
       "4                                       Sara Anisi       1 Feb 2024   \n",
       "\n",
       "                                    Publication Link  \\\n",
       "0  https://pureportal.coventry.ac.uk/en/publicati...   \n",
       "1  https://pureportal.coventry.ac.uk/en/publicati...   \n",
       "2  https://pureportal.coventry.ac.uk/en/publicati...   \n",
       "3  https://pureportal.coventry.ac.uk/en/persons/h...   \n",
       "4  https://pureportal.coventry.ac.uk/en/persons/s...   \n",
       "\n",
       "                                     Authors Profile  \n",
       "0  https://pureportal.coventry.ac.uk/en/persons/l...  \n",
       "1  https://pureportal.coventry.ac.uk/en/persons/c...  \n",
       "2  https://pureportal.coventry.ac.uk/en/persons/m...  \n",
       "3  https://pureportal.coventry.ac.uk/en/persons/h...  \n",
       "4  https://pureportal.coventry.ac.uk/en/persons/s...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_db = sample_db.copy()\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df.Title = df.Title.apply(tp1)\n",
    "    df.Author = df.Authors.str.lower()\n",
    "    df = df.drop(columns=['Authors','Publication Year'], axis=1)\n",
    "    return df\n",
    "    \n",
    "preprocess_df(processed_db)\n",
    "processed_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self):\n",
    "        self.index = {}\n",
    "\n",
    "    def index_document(self, doc_id, text, field):\n",
    "        # Tokenize text into terms\n",
    "        terms = text.split()\n",
    "        # Update index with terms and corresponding document IDs\n",
    "        for term in terms:\n",
    "            if term not in self.index:\n",
    "                self.index[term] = {}\n",
    "            if doc_id not in self.index[term]:\n",
    "                self.index[term][doc_id] = set()\n",
    "            self.index[term][doc_id].add(field)\n",
    "\n",
    "    def search(self, query, field):\n",
    "        # Tokenize query into terms\n",
    "        terms = query.split()\n",
    "        # Initialize result set with documents containing the first term\n",
    "        results = set(self.index.get(terms[0], {}).keys())\n",
    "        # Iterate through remaining terms and refine results\n",
    "        for term in terms[1:]:\n",
    "            results = results.intersection(self.index.get(term, {}).keys())\n",
    "        # Filter results by selected field\n",
    "        return [doc_id for doc_id in results if field.lower() in df.loc[doc_id].to_string().lower()]\n",
    "df = processed_db\n",
    "data = {\n",
    "    \"SN\": df['SN'].tolist(),\n",
    "    \"Title\": df['Title'].tolist(),\n",
    "    \"Authors\": df['Authors'].tolist(),\n",
    "    \"Publication Year\":df['Publication Year'].tolist(),\n",
    "    \"Publication Link\":df['Publication Link'].tolist(),\n",
    "    \"Authors Profile\":df['Authors Profile'].tolist()\n",
    "    \n",
    "    \n",
    "}\n",
    "# Initialize an inverted index\n",
    "index = InvertedIndex()\n",
    "\n",
    "# Indexing publications dynamically based on field\n",
    "def index_based_on_field(field):\n",
    "    index.index = {}\n",
    "    for doc_id, row in df.iterrows():\n",
    "        publication_data = row[field]\n",
    "        index.index_document(doc_id, publication_data, field)\n",
    "\n",
    "# Example usage\n",
    "field_to_index = \"Title\"  # Change this to \"Authors\" to index based on authors\n",
    "index_based_on_field(field_to_index)\n",
    "\n",
    "# Create a Tkinter application\n",
    "root = tk.Tk()\n",
    "root.title(\"Inverted Index Search\")\n",
    "\n",
    "# Create a frame to hold the search input and results\n",
    "frame = ttk.Frame(root, padding=\"10\")\n",
    "frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "# Create a label for the search query\n",
    "ttk.Label(frame, text=\"Search Query:\").grid(row=0, column=0, padx=5, pady=5, sticky=tk.W)\n",
    "query_entry = ttk.Entry(frame, width=50)\n",
    "query_entry.grid(row=0, column=1, padx=5, pady=5, sticky=(tk.W, tk.E))\n",
    "\n",
    "# Create a dropdown menu for selecting the search field\n",
    "selected_field = tk.StringVar()\n",
    "selected_field.set(\"Title\")\n",
    "def update_selected_field(value):\n",
    "    global field_to_index\n",
    "    selected_field.set(value)\n",
    "    field_to_index = value\n",
    "    index_based_on_field(field_to_index)  # Re-index based on the selected field\n",
    "field_options = [\"Title\", \"Authors\"]\n",
    "field_dropdown = ttk.OptionMenu(frame, selected_field, *field_options, command=update_selected_field)\n",
    "field_dropdown.grid(row=0, column=2, padx=5, pady=5, sticky=tk.E)\n",
    "\n",
    "# Create a treeview to display search results in table format\n",
    "result_columns = list(df.columns)\n",
    "result_tree = ttk.Treeview(frame, columns=result_columns, show=\"headings\")\n",
    "for col in result_columns:\n",
    "    result_tree.heading(col, text=col)\n",
    "result_tree.grid(row=1, column=0, columnspan=3, padx=5, pady=5, sticky=(tk.W, tk.E))\n",
    "\n",
    "# Function to handle search button click event\n",
    "def search():\n",
    "    query = query_entry.get()\n",
    "    field = selected_field.get()\n",
    "    results = index.search(query, field)\n",
    "    result_tree.delete(*result_tree.get_children())\n",
    "    for doc_id in results:\n",
    "        row_data = df.loc[[doc_id]].values.tolist()[0]\n",
    "        result_tree.insert(\"\", \"end\", values=row_data)\n",
    "\n",
    "# Create a search button\n",
    "search_button = ttk.Button(frame, text=\"Search\", command=search)\n",
    "search_button.grid(row=0, column=3, padx=5, pady=5, sticky=tk.E)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c51f16fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'ANTIALIAS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Load and resize the logo\u001b[39;00m\n\u001b[0;32m     53\u001b[0m logo_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoventry-university-logo.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m logo_image \u001b[38;5;241m=\u001b[39m logo_image\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m), Image\u001b[38;5;241m.\u001b[39mANTIALIAS)\n\u001b[0;32m     55\u001b[0m logo_photo \u001b[38;5;241m=\u001b[39m ImageTk\u001b[38;5;241m.\u001b[39mPhotoImage(logo_image)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Create a frame to hold the search input and results\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'ANTIALIAS'"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import pandas as pd\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self):\n",
    "        self.index = {}\n",
    "\n",
    "    def index_document(self, doc_id, text, field):\n",
    "        # Tokenize text into terms\n",
    "        terms = text.split()\n",
    "        # Update index with terms and corresponding document IDs\n",
    "        for term in terms:\n",
    "            if term not in self.index:\n",
    "                self.index[term] = {}\n",
    "            if doc_id not in self.index[term]:\n",
    "                self.index[term][doc_id] = set()\n",
    "            self.index[term][doc_id].add(field)\n",
    "\n",
    "    def search(self, query, field):\n",
    "        # Tokenize query into terms\n",
    "        terms = query.split()\n",
    "        # Initialize result set with documents containing the first term\n",
    "        results = set(self.index.get(terms[0], {}).keys())\n",
    "        # Iterate through remaining terms and refine results\n",
    "        for term in terms[1:]:\n",
    "            results = results.intersection(self.index.get(term, {}).keys())\n",
    "        # Filter results by selected field\n",
    "        return [doc_id for doc_id in results if field.lower() in df.loc[doc_id].to_string().lower()]\n",
    "\n",
    "df = sample_db\n",
    "\n",
    "# Initialize an inverted index\n",
    "index = InvertedIndex()\n",
    "\n",
    "# Indexing publications dynamically based on field\n",
    "def index_based_on_field(field):\n",
    "    index.index = {}\n",
    "    for doc_id, row in df.iterrows():\n",
    "        publication_data = row[field]\n",
    "        index.index_document(doc_id, publication_data, field)\n",
    "\n",
    "# Example usage\n",
    "field_to_index = \"Title\"  # Change this to \"Authors\" to index based on authors\n",
    "index_based_on_field(field_to_index)\n",
    "\n",
    "# Create a Tkinter application\n",
    "root = tk.Tk()\n",
    "root.title(\"Inverted Index Search\")\n",
    "\n",
    "# Load and resize the logo\n",
    "logo_image = Image.open(\"coventry-university-logo.png\")\n",
    "logo_image = logo_image.resize((100, 100), Image.ANTIALIAS)\n",
    "logo_photo = ImageTk.PhotoImage(logo_image)\n",
    "\n",
    "# Create a frame to hold the search input and results\n",
    "frame = ttk.Frame(root, padding=\"10\")\n",
    "frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "# Display the logo in the top left corner\n",
    "logo_label = ttk.Label(frame, image=logo_photo)\n",
    "logo_label.image = logo_photo  # Keep a reference\n",
    "logo_label.grid(row=0, column=0, padx=5, pady=5, sticky=tk.W)\n",
    "\n",
    "# Search Engine Title Label\n",
    "search_engine_label = ttk.Label(frame, text=\"Search engine\", font=(\"Arial Bold\", 18))\n",
    "search_engine_label.grid(row=0, column=1, padx=5, pady=5, sticky=tk.W)\n",
    "\n",
    "# Create a label for the search query\n",
    "ttk.Label(frame, text=\"Search Query:\").grid(row=1, column=0, padx=5, pady=5, sticky=tk.W)\n",
    "query_entry = ttk.Entry(frame, width=50)\n",
    "query_entry.grid(row=1, column=1, padx=5, pady=5, sticky=(tk.W, tk.E))\n",
    "\n",
    "# Create a dropdown menu for selecting the search field\n",
    "selected_field = tk.StringVar()\n",
    "selected_field.set(\"Title\")\n",
    "def update_selected_field(value):\n",
    "    global field_to_index\n",
    "    selected_field.set(value)\n",
    "    field_to_index = value\n",
    "    index_based_on_field(field_to_index)  # Re-index based on the selected field\n",
    "field_options = [\"Title\", \"Authors\"]\n",
    "field_dropdown = ttk.OptionMenu(frame, selected_field, *field_options, command=update_selected_field)\n",
    "field_dropdown.grid(row=1, column=2, padx=5, pady=5, sticky=tk.E)\n",
    "\n",
    "# Create a treeview to display search results in table format\n",
    "result_columns = list(df.columns)\n",
    "result_tree = ttk.Treeview(frame, columns=result_columns, show=\"headings\")\n",
    "for col in result_columns:\n",
    "    result_tree.heading(col, text=col)\n",
    "result_tree.grid(row=2, column=0, columnspan=3, padx=5, pady=5, sticky=(tk.W, tk.E))\n",
    "\n",
    "# Function to handle search button click event\n",
    "def search():\n",
    "    query = query_entry.get()\n",
    "    field = selected_field.get()\n",
    "    results = index.search(query, field)\n",
    "    result_tree.delete(*result_tree.get_children())\n",
    "    for doc_id in results:\n",
    "        row_data = df.loc[[doc_id]].values.tolist()[0]\n",
    "        result_tree.insert(\"\", \"end\", values=row_data)\n",
    "\n",
    "# Create a search button\n",
    "search_button = ttk.Button(frame, text=\"Search\", command=search)\n",
    "search_button.grid(row=1, column=3, padx=5, pady=5, sticky=tk.E)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fba0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
